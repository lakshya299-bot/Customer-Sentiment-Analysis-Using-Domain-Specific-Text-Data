# Customer-Sentiment-Analysis
### Domain-Adaptive Transformer Models

## Overview
This project reframes **sentiment analysis** as a **customer insight and feedback understanding** problem rather than a purely text classification task.  
The goal is to capture **domain-specific sentiment patterns** present in long-form movie reviews, which are often missed by generic pretrained language models.

An **end-to-end NLP pipeline** was built using transformer architectures, combining:
- Exploratory analysis of large-scale unlabeled text  
- Domain-adaptive pretraining via Masked Language Modeling (MLM)  
- Supervised fine-tuning for binary sentiment classification  

The final system was **containerized with Docker** and deployed on **Azure App Service (Linux)** to simulate a production-ready NLP workflow.

---

## Problem Motivation
Generic pretrained language models often struggle with:
- Domain-specific vocabulary usage  
- Subtle sentiment cues such as **sarcasm and irony**  
- Contextual sentiment shifts common in long customer reviews  

This project investigates whether **domain-adaptive pretraining** improves sentiment reliability for downstream **customer insight and feedback analysis** tasks.

---

## ðŸ“‚ Dataset
### Large Movie Review Dataset v1.0 (IMDB)

**Key Characteristics**
- **50,000 labeled reviews**
  - 25,000 training  
  - 25,000 testing  
  - Balanced polarity (25k positive, 25k negative)
- **50,000 unlabeled reviews** used for unsupervised learning
- Train and test splits contain **disjoint movies** (prevents leakage)
- Maximum **30 reviews per movie** to reduce correlation bias

**Label Definition**
- Positive â†’ Rating â‰¥ 7  
- Negative â†’ Rating â‰¤ 4  
- Neutral reviews excluded from supervised splits

**Directory Structure**
